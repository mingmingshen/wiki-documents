"use strict";(self.webpackChunkclassic=self.webpackChunkclassic||[]).push([[4041],{43821:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>c,contentTitle:()=>d,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>a});const s=JSON.parse('{"id":"NeoEdge NG4500 Series/NG4500-CB01 Development Board/Software Guide/Driver Installation and Updates/ov5647","title":"OV5647","description":"This document mainly introduces the development and adaptation process of the camera, taking OV5647 as an example.","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/1-NeoEdge NG4500 Series/2-NG4500-CB01 Development Board/2-Software Guide/1-Driver Installation and Updates/3-ov5647.md","sourceDirName":"1-NeoEdge NG4500 Series/2-NG4500-CB01 Development Board/2-Software Guide/1-Driver Installation and Updates","slug":"/NeoEdge NG4500 Series/NG4500-CB01 Development Board/Software Guide/Driver Installation and Updates/ov5647","permalink":"/wiki-documents/docs/NeoEdge NG4500 Series/NG4500-CB01 Development Board/Software Guide/Driver Installation and Updates/ov5647","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"WIFI","permalink":"/wiki-documents/docs/NeoEdge NG4500 Series/NG4500-CB01 Development Board/Software Guide/Driver Installation and Updates/wifi"},"next":{"title":"ALC5640","permalink":"/wiki-documents/docs/NeoEdge NG4500 Series/NG4500-CB01 Development Board/Software Guide/Driver Installation and Updates/ALC5640"}}');var i=n(74848),t=n(28453);const o={},d="OV5647",c={},a=[{value:"Camera Architecture Overview",id:"camera-architecture-overview",level:2},{value:"Common Terms",id:"common-terms",level:3},{value:"Camera SW\xa0Architecture",id:"camera-swarchitecture",level:3},{value:"OV5647 Driver Adaptation Process",id:"ov5647-driver-adaptation-process",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Device Tree Configuration",id:"device-tree-configuration",level:3},{value:"Driver Configuration",id:"driver-configuration",level:3},{value:"System Adaptation",id:"system-adaptation",level:3},{value:"Debugging Ideas",id:"debugging-ideas",level:3},{value:"References",id:"references",level:2}];function l(e){const r={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(r.header,{children:(0,i.jsx)(r.h1,{id:"ov5647",children:"OV5647"})}),"\n",(0,i.jsx)(r.p,{children:"This document mainly introduces the development and adaptation process of the camera, taking OV5647 as an example."}),"\n",(0,i.jsx)(r.h2,{id:"camera-architecture-overview",children:"Camera Architecture Overview"}),"\n",(0,i.jsx)(r.h3,{id:"common-terms",children:"Common Terms"}),"\n",(0,i.jsxs)(r.table,{children:[(0,i.jsx)(r.thead,{children:(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.th,{children:"Term"}),(0,i.jsx)(r.th,{children:"Explanation"})]})}),(0,i.jsxs)(r.tbody,{children:[(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:"ISP"}),(0,i.jsx)(r.td,{children:"Image Signal Processor, used for image denoising, white balance, color correction, etc."})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:"Bayer"}),(0,i.jsx)(r.td,{children:"Camera sensor that captures images using a Bayer filter array."})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:"CSI"}),(0,i.jsx)(r.td,{children:"Camera Serial Interface, used for data transmission between the camera and the processor."})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:"V4L2"}),(0,i.jsx)(r.td,{children:"Linux kernel framework for video capture and output."})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:"libargus"}),(0,i.jsx)(r.td,{children:"NVIDIA's advanced camera control library."})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:"Camera Core Library"}),(0,i.jsx)(r.td,{children:"Provides control and processing functions between application programs and kernel-mode V4L2 drivers."})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:"GStreamer"}),(0,i.jsx)(r.td,{children:"Open-source multimedia processing framework for audio and video processing."})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:"Host1x"}),(0,i.jsx)(r.td,{children:"Host interface controller in NVIDIA Tegra SoC."})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:"Aperture"}),(0,i.jsx)(r.td,{children:"Aperture control for adjusting the lens aperture size."})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:"UVC"}),(0,i.jsx)(r.td,{children:"USB Video Class, used for USB camera drivers."})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:"VI"}),(0,i.jsx)(r.td,{children:"Video Input module for receiving and processing video data."})]})]})]}),"\n",(0,i.jsx)(r.h3,{id:"camera-swarchitecture",children:"Camera SW\xa0Architecture"}),"\n",(0,i.jsxs)(r.p,{children:["\xa0\xa0\xa0\xa0NVIDIA platform provides two camera driver architectures: ",(0,i.jsx)(r.strong,{children:"Camera Core Library Interface"})," and ",(0,i.jsx)(r.strong,{children:"Direct V4L2 Interface"}),". The main difference is that the former provides access to the ISP on the Jetson platform and advanced image processing functions, and exports related interfaces for libargus usage in the application space. Libargus provides simplified APIs for accessing camera functions and ISP on the Jetson platform. The nvgstcapture-1.0 tool used later is also based on this library.\r\nSince we need to use NVIDIA-related ISP functions later, we will develop and adapt the Camera Core Library Interface framework."]}),"\n",(0,i.jsx)(r.h2,{id:"ov5647-driver-adaptation-process",children:"OV5647 Driver Adaptation Process"}),"\n",(0,i.jsx)(r.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsx)(r.p,{children:"Obtain the camera I2C address, confirm the wiring sequence, power and reset pins."}),"\n"]}),"\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsx)(r.p,{children:"Obtain the camera power-on sequence, clock, supported resolutions, frame rates, and camera filter array (BGGR, GBRG, GRBG, RGGB)."}),"\n"]}),"\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsxs)(r.p,{children:["Confirm the camera connection interface, corresponding to the appropriate ",(0,i.jsx)(r.code,{children:"tegra_sinterface"}),", such as cam1 corresponding to serial_a and cam0 corresponding to serial_c on Jetson Orin NX."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(r.p,{children:(0,i.jsx)(r.strong,{children:"This adaptation is based on the Jetson Orin NX platform, and the hardware connection interface is cam0."})}),"\n",(0,i.jsx)(r.h3,{id:"device-tree-configuration",children:"Device Tree Configuration"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsx)(r.p,{children:"The DTB of OV5647 is loaded using the overlay method, so create a DTS file in the kernel source code, the path is as follows:"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-shell",children:"Linux_for_Tegra/source/hardware/nvidia/t23x/nv-public/overlay/tegra234-p3767-camera-p3768-ov5647.dts`\n"})}),"\n"]}),"\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsxs)(r.p,{children:["Create the\xa0",(0,i.jsx)(r.code,{children:"tegra-camera-platform"}),"\xa0device tree node"]}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-nand2tetris-hdl",children:"tegra-capture-vi  {\r\n    num-channels = <1>;\r\n    ports {\r\n        #address-cells = <1>;\r\n        #size-cells = <0>;\r\n        vi_port1: port@1 {\r\n            reg = <0>;\r\n            rbpcv2_ov5647_vi_in1: endpoint {\r\n                port-index = <2>;\r\n                bus-width = <2>;\r\n                remote-endpoint = <&rbpcv2_ov5647_csi_out1>;\r\n            };\r\n        };\r\n    };\r\n};\n"})}),"\n"]}),"\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsxs)(r.p,{children:["Create\xa0",(0,i.jsx)(r.code,{children:"rbpcv2_ov5647_c@36"}),"\xa0device under the I2C node and fill in the I2C device address, mode clock, resolution, frame rate, etc. according to the datasheet"]}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-nand2tetris-hdl",children:'rbpcv2_ov5647_c@36 {\r\n    reset-gpios = <&gpio CAM0_RST GPIO_ACTIVE_HIGH>;\r\n    pwdn-gpios = <&gpio CAM1_PWDN GPIO_ACTIVE_HIGH>;\r\n    compatible = "ovti,ov5647";\r\n    /* I2C device address */\r\n    reg = <0x36>;\r\n    /* V4L2 device node loation */\r\n    devnode = "video0";\r\n    /* Physical dimensions of sensor */\r\n    physical_w = "3.670";\r\n    physical_h = "2.740";\r\n    sensor_model = "ov5647";\r\n    use_sensor_mode_id = "true";\r\n\r\n    clocks = <&bpmp TEGRA234_CLK_EXTPERIPH2>,\r\n            <&bpmp TEGRA234_CLK_PLLP_OUT0>;\r\n    clock-names = "extperiph2", "pllp_grtba";\r\n    mclk = "extperiph2";\r\n    clock-frequency = <24000000>;\r\n\r\n    mode0 { /* ov5647_MODE0_1920x1080_30FPS */\r\n        mclk_khz = "25000";\r\n        num_lanes = "2";\r\n        // lane_polarity = "4";\r\n        tegra_sinterface = "serial_c";\r\n        phy_mode = "DPHY";\r\n        discontinuous_clk = "yes";\r\n        dpcm_enable = "false";\r\n        cil_settletime = "0";\r\n        active_w = "1920";\r\n        active_h = "1080";\r\n        mode_type = "bayer";\r\n        pixel_phase = "bggr";\r\n        csi_pixel_bit_depth = "10";\r\n        readout_orientation = "90";\r\n        line_length = "2416";\r\n        inherent_gain = "1";\r\n        mclk_multiplier = "3.6669";\r\n        pix_clk_hz = "81666663";\r\n        gain_factor = "16";\r\n        framerate_factor = "1000000";\r\n        exposure_factor = "1000000";\r\n        min_gain_val = "16";\r\n        max_gain_val = "128";\r\n        step_gain_val = "1";\r\n        default_gain = "16";\r\n        min_hdr_ratio = "1";\r\n        max_hdr_ratio = "1";\r\n        min_framerate = "30000000"; /* 30.0 fps */\r\n        max_framerate = "30000000"; /* 30.0 fps */\r\n        step_framerate = "1";\r\n        default_framerate = "45000000"; /* 30.0 fps */\r\n        min_exp_time = "60"; /* us */\r\n        max_exp_time = "30000"; /* us */\r\n        step_exp_time = "1";\r\n        default_exp_time = "10000"; /* us */\r\n        embedded_metadata_height = "0";\r\n    };\r\n\r\n    ........................\r\n\r\n    ports {\r\n        #address-cells = <1>;\r\n        #size-cells = <0>;\r\n        port@0 {\r\n            reg = <0>;\r\n            rbpcv2_ov5647_out1: endpoint {\r\n                status = "okay";\r\n                port-index = <1>;\r\n                bus-width = <2>;\r\n                remote-endpoint = <&rbpcv2_ov5647_csi_in1>;\r\n            };\r\n        };\r\n    };\r\n\r\n};\n'})}),"\n"]}),"\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsx)(r.p,{children:"Port binding configuration to ensure the video stream connection relationship."}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsx)(r.p,{children:"The video data stream is generated from the OV5647 camera device, then transmitted to the CSI module for receiving, decoding, deserializing, and preliminary processing of video data. It is then transmitted to the VI module for further processing and formatting of video data, and finally transmitted to system memory or other processing units."}),"\n"]}),"\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsxs)(r.p,{children:["Connect the three modules through\xa0",(0,i.jsx)(r.code,{children:"remote-endpoint"}),"."]}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-nand2tetris-hdl",children:"tegra-capture-vi  {\r\n    num-channels = <1>;\r\n    ports {\r\n        #address-cells = <1>;\r\n        #size-cells = <0>;\r\n        vi_port1: port@1 {\r\n            reg = <0>;\r\n            rbpcv2_ov5647_vi_in1: endpoint {\r\n                port-index = <2>;\r\n                bus-width = <2>;\r\n                remote-endpoint = <&rbpcv2_ov5647_csi_out1>;\r\n            };\r\n        };\r\n    };\r\n}; \r\n\r\nhost1x@13e00000 {\r\n    nvcsi@15a00000 {\r\n        num-channels = <1>;\r\n        #address-cells = <1>;\r\n        #size-cells = <0>;\r\n        csi_chan1: channel@1 {\r\n            reg = <0>;\r\n            ports {\r\n                #address-cells = <1>;\r\n                #size-cells = <0>;\r\n                csi_chan1_port0: port@0 {\r\n                    reg = <0>;\r\n                    rbpcv2_ov5647_csi_in1: endpoint@2 {\r\n                        port-index = <2>;\r\n                        bus-width = <2>;\r\n                        remote-endpoint = <&rbpcv2_ov5647_out1>;\r\n                    };\r\n                };\r\n                csi_chan1_port1: port@1 {\r\n                    reg = <1>;\r\n                    rbpcv2_ov5647_csi_out1: endpoint@3 {\r\n                        remote-endpoint = <&rbpcv2_ov5647_vi_in1>;\r\n                    };\r\n                };\r\n            };\r\n        };\r\n    };\r\n};\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsxs)(r.p,{children:["Configure Makefile,\xa0",(0,i.jsx)(r.code,{children:"/home/xuys8233/work/Linux_for_Tegra/source/hardware/nvidia/t23x/nv-public/overlay/Makefile"}),", add the following information:"]}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{children:"dtbo-y += tegra234-p3767-camera-p3768-ov5647.dtbo\n"})}),"\n"]}),"\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsx)(r.p,{children:"Compile to generate dtbo"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{children:"make dtbs\n"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(r.h3,{id:"driver-configuration",children:"Driver Configuration"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsxs)(r.p,{children:["Add the driver file\xa0",(0,i.jsx)(r.code,{children:"/home/xuys8233/work/Linux_for_Tegra/source/nvidia-oot/drivers/media/i2c/ov5647.c"}),". This driver file can be modified based on\xa0",(0,i.jsx)(r.code,{children:"nv_ov5693.c"}),". The core points are as follows:"]}),"\n"]}),"\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsxs)(r.p,{children:["Register the camera driver through the NVIDIA provided\xa0",(0,i.jsx)(r.code,{children:"tegracam_device_register"}),"\xa0function. The following three structures need to be filled:"]}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsxs)(r.p,{children:[(0,i.jsx)(r.code,{children:"tc_dev->sensor_ops"}),", this structure contains the sensor-related operation functions, such as power on, power off, read and write registers, set mode, start and stop streaming, etc. These functions will be called when using NVIDIA's libargus API. Here is an example of this structure:"]}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-c",children:"static struct tegracam_sensor_ops ov5647_sensor_ops = {\r\n    .power_on = ov5647_power_on,\r\n    .power_off = ov5647_power_off,\r\n    .write_reg = ov5647_write_reg,\r\n    .read_reg = ov5647_read_reg,\r\n    .set_mode = ov5647_set_mode,\r\n    .start_streaming = ov5647_start_streaming,\r\n    .stop_streaming = ov5647_stop_streaming,\r\n    .sensor_init = ov5647_sensor_init,\r\n};\n"})}),"\n",(0,i.jsx)(r.p,{children:"The specific implementation of these functions needs to be written according to the OV5647 datasheet and related documents."}),"\n"]}),"\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsxs)(r.p,{children:[(0,i.jsx)(r.code,{children:"tc_dev->v4l2sd_internal_ops"}),", this structure mainly implements the\xa0",(0,i.jsx)(r.code,{children:"open"}),"\xa0function. If you need to use\xa0",(0,i.jsx)(r.code,{children:"v4l2-ctl"}),"\xa0related tools in user space, you need to add\xa0",(0,i.jsx)(r.code,{children:".s_stream = ov5647_s_stream"}),"\xa0related function. Here is an example:"]}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-c",children:"static struct v4l2_subdev_internal_ops ov5647_subdev_internal_ops = {\r\n    .open = ov5647_open,\r\n};\n"})}),"\n"]}),"\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsxs)(r.p,{children:[(0,i.jsx)(r.code,{children:"tc_dev->tcctrl_ops"}),", this structure contains the camera control operation functions, such as setting gain, exposure, frame rate, etc. Here is an example:"]}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-c",children:"static struct tegracam_ctrl_ops ov5647_ctrl_ops = {\r\n    .numctrls = ARRAY_SIZE(ctrl_cid_list),\r\n    .ctrl_cid_list = ctrl_cid_list,\r\n    .set_gain = ov5647_set_gain,\r\n    .set_exposure = ov5647_set_exposure,\r\n    .set_frame_rate = ov5647_set_frame_rate,\r\n    .set_group_hold = ov5647_set_group_hold,\r\n};\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsxs)(r.p,{children:["Add the header file\xa0",(0,i.jsx)(r.code,{children:"/home/xuys8233/work/Linux_for_Tegra/source/nvidia-oot/drivers/media/i2c/ov5647_modes_tbls.h"}),", which mainly contains the register tables for sensor resolution, exposure time, etc. Here is an example:"]}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsxs)(r.p,{children:["This table will be registered by the\xa0",(0,i.jsx)(r.code,{children:"tc_dev->sensor_ops"}),"\xa0structure."]}),"\n"]}),"\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsxs)(r.p,{children:["Then configure the register table for each resolution, such as\xa0",(0,i.jsx)(r.code,{children:"start_stream"}),". Subsequent functions like\xa0",(0,i.jsx)(r.code,{children:"set_mode"}),",\xa0",(0,i.jsx)(r.code,{children:"set_gain"}),", etc., will call the register configuration in this table for writing. (",(0,i.jsx)(r.strong,{children:"Note: The order of each resolution needs to be consistent with the mode order in the device tree"}),")"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsxs)(r.p,{children:["Configure Makefile, modify\xa0",(0,i.jsx)(r.code,{children:"/home/xuys8233/work/Linux_for_Tegra/source/nvidia-oot/drivers/media/i2c/Makefile"})]}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-shell",children:"obj-m += ov5647.o\n"})}),"\n"]}),"\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsxs)(r.p,{children:["Compile the module to generate\xa0",(0,i.jsx)(r.code,{children:"ov5647.ko"})]}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-shell",children:"make modules\n"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(r.h3,{id:"system-adaptation",children:"System Adaptation"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:["Start the device, copy the compiled dtbo and\xa0",(0,i.jsx)(r.code,{children:"ov5647.ko"}),"\xa0to the AIBOX via scp."]}),"\n"]}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{children:"cd Linux_for_Tegra/source\r\n\r\nscp ./kernel-devicetree/generic-dts/dtbs/tegra234-p3767-camera-p3768-ov5647.dtbo milesight@192.168.60.3:/home/milesight\r\nscp ./kernel-devicetree/generic-dts/dtbs/tegra234-p3767-camera-p3768-ov5647.dtbo milesight@192.168.60.3:/home/milesight\n"})}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:["Copy\xa0",(0,i.jsx)(r.code,{children:"ov5647.ko"}),"\xa0to the modules directory and execute\xa0",(0,i.jsx)(r.code,{children:"depmod"}),"\xa0to load the driver."]}),"\n"]}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{children:"sudo cp ./ov5647.ko  /usr/lib/modules/5.15.148-tegra/updates/drivers/media/i2c/\r\n\r\ndepmod\n"})}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsxs)(r.p,{children:["Copy the dtbo to the /boot directory and start the dtbo using\xa0",(0,i.jsx)(r.code,{children:"config-by-hardware.py"}),", as shown below."]}),"\n"]}),"\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsx)(r.p,{children:"After completing, restart the development board."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(r.h3,{id:"debugging-ideas",children:"Debugging Ideas"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsx)(r.p,{children:"Confirm if the dtbo is loaded successfully"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:["Execute\xa0",(0,i.jsx)(r.code,{children:"cat /boot/extlinux/extlinux.conf"}),"\xa0to confirm if the dtbo is loaded."]}),"\n",(0,i.jsxs)(r.li,{children:["Execute\xa0",(0,i.jsx)(r.code,{children:"cat /proc/device-tree/tegra-camera-platform/modules/module1/drivernode0/sysfs-device-tree"}),"\xa0to confirm if the dtbo is effective. (The dtbo may be configured in extlinux.conf but not necessarily used. Errors in the dtbo may prevent it from taking effect, and such errors will not be displayed, so this step is necessary.)"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsx)(r.p,{children:"Confirm if the driver is loaded successfully"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:["Execute\xa0",(0,i.jsx)(r.code,{children:"lsmod | grep ov5647"}),"\xa0to confirm if the ov5647 driver is present."]}),"\n",(0,i.jsxs)(r.li,{children:["Execute\xa0",(0,i.jsx)(r.code,{children:"sudo dmesg | grep ov5647"}),"\xa0to check for errors during driver loading."]}),"\n",(0,i.jsxs)(r.li,{children:["Use\xa0",(0,i.jsx)(r.code,{children:"sudo i2cdetect -y -r 9"}),"\xa0to confirm if the device matches successfully."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsxs)(r.p,{children:["After confirming no issues, run\xa0",(0,i.jsx)(r.code,{children:"nvgstcapture-1.0"}),"\xa0to call the sensor."]}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsx)(r.li,{children:"Confirm if the listed resolutions match the modes in the device tree."}),"\n",(0,i.jsxs)(r.li,{children:["Check for other error messages. If\xa0",(0,i.jsx)(r.code,{children:"nvbuf_utils"}),"\xa0appears, check for error messages in dmesg."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(r.li,{children:["\n",(0,i.jsxs)(r.p,{children:["Use\xa0",(0,i.jsx)(r.code,{children:"sudo media-ctl -p -d /dev/media0"}),"\xa0to check for issues in the video stream link."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(r.h2,{id:"references",children:"References"}),"\n",(0,i.jsx)(r.p,{children:(0,i.jsx)(r.a,{href:"https://docs.nvidia.com/jetson/archives/r36.3/DeveloperGuide/SD/CameraDevelopment/SensorSoftwareDriverProgramming.html",children:"Sensor Software Driver Programming"})}),"\n",(0,i.jsx)(r.p,{children:(0,i.jsx)(r.a,{href:"https://github.com/mkm684/ov5647_driver/blob/main/ov5647.c",children:"ov5647_driver/ov5647.c at main \xb7 mkm684/ov5647_driver"})})]})}function h(e={}){const{wrapper:r}={...(0,t.R)(),...e.components};return r?(0,i.jsx)(r,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},28453:(e,r,n)=>{n.d(r,{R:()=>o,x:()=>d});var s=n(96540);const i={},t=s.createContext(i);function o(e){const r=s.useContext(t);return s.useMemo((function(){return"function"==typeof e?e(r):{...r,...e}}),[r,e])}function d(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),s.createElement(t.Provider,{value:r},e.children)}}}]);